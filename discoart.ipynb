{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4a6587",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/jina-ai/discoart/blob/main/.github/banner.png?raw=true\" alt=\"Create Disco Diffusion artworks in one-line\">\n",
    "<p align=center>\n",
    "<a href=\"https://pypi.org/project/discoart/\"><img src=\"https://img.shields.io/pypi/v/discoart?style=flat-square&amp;label=Release\" alt=\"PyPI\"></a>\n",
    "<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n",
    "<a href=\"https://colab.research.google.com/github/jina-ai/dalle-flow/blob/main/client.ipynb\"><img src=\"https://img.shields.io/badge/Open-in%20Colab-brightgreen?logo=google-colab&style=flat-square\" alt=\"Open in Google Colab\"/></a>\n",
    "</p>\n",
    "\n",
    "😎 **If you are already a DD user**: you are ready to go! There is no extra learning, DiscoArt respects the same parameter semantics as DD5.2. So just unleash your creativity! [Read more about DiscoArt vs. DD5.5](https://github.com/jina-ai/discoart/blob/main/FEATURES.md)\n",
    "\n",
    "You can always do `from discoart import cheatsheet; cheatsheet()` to check all new/modified parameters, DiscoArt specific parameters are highlighted in the cheatsheet. \n",
    "\n",
    "\n",
    "\n",
    "👶 **If you are a [DALL·E Flow](https://github.com/jina-ai/dalle-flow/) or new user**: you may want to take step by step, as Disco Diffusion works in a very different way than DALL·E. It is much more advanced and powerful: e.g. Disco Diffusion can take weighted & structured text prompts; it can initialize from a image with controlled noise; and there are way more parameters one can tweak. Impatient prompt like `\"armchair avocado\"` will give you nothing but confusion and frustration. I highly recommend you to check out the following resources before trying your own prompt:\n",
    "- [Zippy's Disco Diffusion Cheatsheet v0.3](https://docs.google.com/document/d/1l8s7uS2dGqjztYSjPpzlmXLjl5PM3IGkRWI3IiCuK7g/mobilebasic)\n",
    "- [EZ Charts - Diffusion Parameter Studies](https://docs.google.com/document/d/1ORymHm0Te18qKiHnhcdgGp-WSt8ZkLZvow3raiu2DVU/edit#)\n",
    "- [Disco Diffusion 70+ Artist Studies](https://weirdwonderfulai.art/resources/disco-diffusion-70-plus-artist-studies/)\n",
    "- [A Traveler’s Guide to the Latent Space](https://sweet-hall-e72.notion.site/A-Traveler-s-Guide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f#e122e748b86e4fc0ad6a7a50e46d6e10)\n",
    "- [Disco Diffusion Illustrated Settings](https://coar.notion.site/Disco-Diffusion-Illustrated-Settings-cd4badf06e08440c99d8a93d4cd39f51)\n",
    "- [Coar’s Disco Diffusion Guide](https://coar.notion.site/coar/Coar-s-Disco-Diffusion-Guide-3d86d652c15d4ca986325e808bde06aa#8a3c6e9e4b6847afa56106eacb6f1f79)\n",
    "\n",
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca392ef6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U discoart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36983b6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf748c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from discoart import create\n",
    "\n",
    "da = create(\n",
    "       n_batches = 2,\n",
    "       text_prompts = 'A Chinese dragon is above the terraced fields, greg rutkowski, Thomas kinkade, artstation.',\n",
    "       width_height = [1280, 720],\n",
    "       steps = 250,\n",
    "       batch_size = 2,\n",
    "       skip_steps = 10,\n",
    "       display_rate = 10,\n",
    "       )\n",
    "\n",
    "# 运行下方「Check parameter cheatsheet」代码块，可查询参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac122d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check parameter cheatsheet\n",
    "\n",
    "But what parameters can be used in `create()`? just type `cheatsheet()` to lookup anytime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6c8306",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Cheatsheet for all supported parameters                                      </span>\n",
       "╭────────────────────────────┬────────────┬───────────────────────────────────────────────────────────────────────╮\n",
       "│<span style=\"font-weight: bold\">                   Argument </span>│<span style=\"font-weight: bold\"> Default    </span>│<span style=\"font-weight: bold\"> Description                                                           </span>│\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 batch_name │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ The name of the batch, the batch id will be named as <span style=\"color: #008000; text-decoration-color: #008000\">\"discoart--\"</span>. To │\n",
       "│                            │            │ avoid your artworks be overridden by other users, please use a unique │\n",
       "│                            │            │ name.                                                                 │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 batch_size │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>          │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The number of samples generated at each steps. Say        │\n",
       "│                            │            │ `<span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>`, then you can generate three images in one run. Not    │\n",
       "│                            │            │ only this is faster than three runs, but it leverages loss function   │\n",
       "│                            │            │ better and potentially yields higher quality images.                  │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ One can of course also do `<span style=\"color: #808000; text-decoration-color: #808000\">n_batches</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` and `<span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>` to         │\n",
       "│                            │            │ generate three images in one run. But using `<span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>` is         │\n",
       "│                            │            │ marginally faster and yield higher quality images.                    │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ High `batch_size` can lead to OOM.                                    │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 clamp_grad │ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>       │ As I understand it, clamp_grad is an internal limiter that stops DD   │\n",
       "│                            │            │ from producing extreme results.  Try your images with and without     │\n",
       "│                            │            │ clamp_grad. If the image changes drastically with clamp_grad turned   │\n",
       "│                            │            │ off, it probably means your clip_guidance_scale is too high and       │\n",
       "│                            │            │ should be reduced.                                                    │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  clamp_max │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>       │ Sets the value of the clamp_grad limitation. Default is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>,         │\n",
       "│                            │            │ providing for smoother, more muted coloration in images, but setting  │\n",
       "│                            │            │ higher values <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.15</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"font-weight: bold\">)</span> can provide interesting contrast and         │\n",
       "│                            │            │ vibrancy.                                                             │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│              clip_denoised │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ Determines whether CLIP discriminates a noisy or denoised image       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        clip_guidance_scale │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>       │ CGS is one of the most important parameters you will use. It tells DD │\n",
       "│                            │            │ how strongly you want CLIP to move toward your prompt each timestep.  │\n",
       "│                            │            │ Higher is generally better, but if CGS is too strong it will          │\n",
       "│                            │            │ overshoot the goal and distort the image. So a happy medium is        │\n",
       "│                            │            │ needed, and it takes experience to learn how to adjust CGS.           │\n",
       "│                            │            │ Note that this parameter generally scales with image dimensions. In   │\n",
       "│                            │            │ other words, if you increase your total dimensions by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>% <span style=\"font-weight: bold\">(</span>e.g. a     │\n",
       "│                            │            │ change from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>, then to maintain the same effect │\n",
       "│                            │            │ on the image, you’d want to increase clip_guidance_scale from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span> to │\n",
       "│                            │            │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7500</span>.                                                                 │\n",
       "│                            │            │ Of the basic settings, clip_guidance_scale, steps and skip_steps are  │\n",
       "│                            │            │ the most important contributors to image quality, so learn them well. │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                clip_models │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'ViT-B-32</span> │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> CLIP Model selectors provided by open-clip package.       │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">::openai'</span>, │                                                                       │\n",
       "│                            │            │ These various CLIP models are available for you to use during image   │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">'ViT-B-16:</span> │ generation.  Models have different styles or ‘flavors,’ so look       │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">:openai'</span>,  │ around.                                                               │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">'RN50::ope</span> │ You can mix in multiple models as well for different results.         │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">nai'</span><span style=\"font-weight: bold\">]</span>      │ However, keep in mind that some models are extremely memory-hungry,   │\n",
       "│                            │            │ and turning on additional models will take additional memory and may  │\n",
       "│                            │            │ cause a crash.                                                        │\n",
       "│                            │            │ Also supported open_clip pretrained models, use `::` to separate      │\n",
       "│                            │            │ model name and pretrained weight name, e.g. `ViT-B/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>::laion2b_e16`.  │\n",
       "│                            │            │ Full list of models and weights can be found here:                    │\n",
       "│                            │            │ <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/mlfoundations/open_clip#pretrained-model-interface</span> │\n",
       "│                            │            │  RN50::openai                                                         │\n",
       "│                            │            │  RN50::yfcc15m                                                        │\n",
       "│                            │            │  RN<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">50::cc12</span>m                                                          │\n",
       "│                            │            │  RN50-quickgelu::openai                                               │\n",
       "│                            │            │  RN50-quickgelu::yfcc15m                                              │\n",
       "│                            │            │  RN50-quickgelu::cc12m                                                │\n",
       "│                            │            │  RN101::openai                                                        │\n",
       "│                            │            │  RN101::yfcc15m                                                       │\n",
       "│                            │            │  RN101-quickgelu::openai                                              │\n",
       "│                            │            │  RN101-quickgelu::yfcc15m                                             │\n",
       "│                            │            │  RN5<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x4</span>::openai                                                       │\n",
       "│                            │            │  RN5<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x16</span>::openai                                                      │\n",
       "│                            │            │  RN5<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x64</span>::openai                                                      │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>::openai                                                     │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>::laion2b_e16                                                │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>::laion400m_e31                                              │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>::laion400m_e32                                              │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-quickgelu::openai                                           │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-quickgelu::laion400m_e31                                    │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-quickgelu::laion400m_e32                                    │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>::openai                                                     │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>::laion400m_e31                                              │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>::laion400m_e32                                              │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>-plus-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span>::laion400m_e31                                     │\n",
       "│                            │            │  ViT-B-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>-plus-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span>::laion400m_e32                                     │\n",
       "│                            │            │  ViT-L-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>::openai                                                     │\n",
       "│                            │            │  ViT-L-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">336</span>::openai                                                 │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│      clip_models_schedules │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> A dictionary of string to boolean list that represents    │\n",
       "│                            │            │ on/off of CLIP models at each step. CLIP Model schedules use a        │\n",
       "│                            │            │ similar mechanism to cut_overview and `cut_innercut`. For example,    │\n",
       "│                            │            │ `<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"RN101::openai\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"[True]*400+[False]*600\"</span><span style=\"font-weight: bold\">}</span>` schedules RN101 to run  │\n",
       "│                            │            │ for the first <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>% of steps and then is no longer used for the         │\n",
       "│                            │            │ remaining steps. `<span style=\"font-weight: bold\">[</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>` is equivalent to always on and is the  │\n",
       "│                            │            │ default if this parameter is not set. Note, the model must be         │\n",
       "│                            │            │ included in the `clip_models` otherwise this parameter is ignored.    │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 cut_ic_pow │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>        │ This sets the size of the border used for inner cuts.  High           │\n",
       "│                            │            │ cut_ic_pow values have larger borders, and therefore the cuts         │\n",
       "│                            │            │ themselves will be smaller and provide finer details.  If you have    │\n",
       "│                            │            │ too many or too-small inner cuts, you may lose overall image          │\n",
       "│                            │            │ coherency and/or it may cause an undesirable ‘mosaic’ effect.   Low   │\n",
       "│                            │            │ cut_ic_pow values will allow the inner cuts to be larger, helping     │\n",
       "│                            │            │ image coherency while still helping with some details.                │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> This can be a list of floats that represents the value a… │\n",
       "│                            │            │ different steps, the syntax follows the same as `cut_overview`.       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_icgray_p │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+ │ In addition to the overall cut schedule, a portion of the cuts can be │\n",
       "│                            │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>    │ set to be grayscale instead of color. This may help with improved     │\n",
       "│                            │            │ definition of shapes and edges, especially in the early diffusion     │\n",
       "│                            │            │ steps where the image structure is being defined.                     │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_innercut │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> │ The schedule of inner cuts, which are smaller cropped images from the │\n",
       "│                            │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>     │ interior of the image, helpful in tuning fine details. The size of    │\n",
       "│                            │            │ the inner cuts can be adjusted using the `cut_ic_pow` parameter.      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_overview │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+<span style=\"font-weight: bold\">[</span> │ The schedule of overview cuts, which take a snapshot of the entire    │\n",
       "│                            │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span>*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>     │ image and evaluate that against the prompt.                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        cut_schedules_group │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The group name of the cut-scheduling. For example,        │\n",
       "│                            │            │ `default` corresponds to                                              │\n",
       "│                            │            │ default:                                                              │\n",
       "│                            │            │   cut_overview: <span style=\"color: #008000; text-decoration-color: #008000\">\"[12]*400+[4]*600\"</span>                                    │\n",
       "│                            │            │   cut_innercut: <span style=\"color: #008000; text-decoration-color: #008000\">\"[4]*400+[12]*600\"</span>                                    │\n",
       "│                            │            │   cut_ic_pow: <span style=\"color: #008000; text-decoration-color: #008000\">\"[1]*1000\"</span>                                              │\n",
       "│                            │            │   cut_icgray_p: <span style=\"color: #008000; text-decoration-color: #008000\">\"[0.2]*400+[0]*600\"</span>                                   │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ There are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> predefined groups: `pad_or_pulp` and `watercolor`.        │\n",
       "│                            │            │ This parameter has less priority than the cut_overview, cut_innercut, │\n",
       "│                            │            │ cut_ic_pow, cut_icgray_p parameters, meaning that one can override    │\n",
       "│                            │            │ cut_overview, cut_innercut, cut_ic_pow, cut_icgray_p by setting them  │\n",
       "│                            │            │ afterwards.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cutn_batches │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>          │ Each iteration, the AI cuts the image into smaller pieces known as    │\n",
       "│                            │            │ cuts, and compares each cut to the prompt to decide how to guide the  │\n",
       "│                            │            │ next diffusion step.  More cuts can generally lead to better images,  │\n",
       "│                            │            │ since DD has more chances to fine-tune the image precision in each    │\n",
       "│                            │            │ timestep.                                                             │\n",
       "│                            │            │ Additional cuts are memory intensive, however, and if DD tries to     │\n",
       "│                            │            │ evaluate too many cuts at once, it can run out of memory.  You can    │\n",
       "│                            │            │ use cutn_batches to increase cuts per timestep without increasing     │\n",
       "│                            │            │ memory usage.                                                         │\n",
       "│                            │            │ At the default settings, DD is scheduled to do <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> cuts per timestep.  │\n",
       "│                            │            │ If cutn_batches is set to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, there will indeed only be <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> cuts total  │\n",
       "│                            │            │ per timestep.                                                         │\n",
       "│                            │            │ However, if cutn_batches is increased to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, DD will do <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> cuts total  │\n",
       "│                            │            │ in each timestep, divided into <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sequential batches of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> cuts each.  │\n",
       "│                            │            │ Because the cuts are being evaluated only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> at a time, DD uses the   │\n",
       "│                            │            │ memory required for only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> cuts, but gives you the quality benefit   │\n",
       "│                            │            │ of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> cuts.  The tradeoff, of course, is that this will take ~<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> times │\n",
       "│                            │            │ as long to render each image.                                         │\n",
       "│                            │            │ So, <span style=\"font-weight: bold\">(</span>scheduled cuts<span style=\"font-weight: bold\">)</span> x <span style=\"font-weight: bold\">(</span>cutn_batches<span style=\"font-weight: bold\">)</span> = <span style=\"font-weight: bold\">(</span>total cuts per timestep<span style=\"font-weight: bold\">)</span>.    │\n",
       "│                            │            │ Increasing cutn_batches will increase render times, however, as the   │\n",
       "│                            │            │ work is being done sequentially.  DD’s default cut schedule is a good │\n",
       "│                            │            │ place to start, but the cut schedule can be adjusted in the Cutn      │\n",
       "│                            │            │ Scheduling section, explained below.                                  │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│            diffusion_model │ 512x512_di │ Diffusion_model of choice. Note that you don't have to write the full │\n",
       "│                            │ ffusion_un │ name of the diffusion model, e.g. any prefix is enough.               │\n",
       "│                            │ cond_finet │                                                                       │\n",
       "│                            │ une_008100 │ To use a listed all diffusion models, you can do:                     │\n",
       "│                            │            │ ```python                                                             │\n",
       "│                            │            │ from discoart import create                                           │\n",
       "│                            │            │ <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">create</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">diffusion_model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'portrait_generator'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">)</span>                     │\n",
       "│                            │            │ ```                                                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│     diffusion_model_config │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The customized diffusion model config as a dictionary, i… │\n",
       "│                            │            │ specified will override the values with the same name in the default  │\n",
       "│                            │            │ model config.                                                         │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│    diffusion_sampling_mode │ ddim       │ Two alternate diffusion denoising algorithms. ddim has been around    │\n",
       "│                            │            │ longer, and is more established and tested.  plms is a newly added    │\n",
       "│                            │            │ alternate method that promises good diffusion results in fewer steps, │\n",
       "│                            │            │ but has not been as fully tested and may have side effects. This new  │\n",
       "│                            │            │ plms mode is actively being researched in the                         │\n",
       "│                            │            │ #settings-and-techniques channel in the DD Discord.                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               display_rate │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>          │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The refresh rate of displaying the generated images in    │\n",
       "│                            │            │ Notebook environment. The value has nothing to do with the rate of    │\n",
       "│                            │            │ saving images and the speed of generation or sampling. It is purely   │\n",
       "│                            │            │ about your browser refreshing. Smaller value <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> is the smallest, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    │\n",
       "│                            │            │ will disable the refresh<span style=\"font-weight: bold\">)</span> will consume more network bandwidth, as     │\n",
       "│                            │            │ your browser will actively fetch refreshed images to local. Change it │\n",
       "│                            │            │ to a bigger value if you have limited network bandwidth.              │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                        eta │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>        │ eta <span style=\"font-weight: bold\">(</span>greek letter η<span style=\"font-weight: bold\">)</span> is a diffusion model variable that mixes in a    │\n",
       "│                            │            │ random amount of scaled noise into each timestep. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> is no noise, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>  │\n",
       "│                            │            │ is more noise. As with most DD parameters, you can go below zero for  │\n",
       "│                            │            │ eta, but it may give you unpredictable results.                       │\n",
       "│                            │            │ The steps parameter has a close relationship with the eta parameter.  │\n",
       "│                            │            │ If you set eta to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, then you can get decent output with only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>   │\n",
       "│                            │            │ steps. Setting eta to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span> favors higher step counts, ideally around   │\n",
       "│                            │            │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span> and up. eta has a subtle, unpredictable effect on image, so       │\n",
       "│                            │            │ you’ll need to experiment to see how this affects your projects.      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                    gif_fps │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>         │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The frame rate of the generated GIF. Set it to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span> for no… │\n",
       "│                            │            │ saving GIF.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│             gif_size_ratio │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>        │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The relative size vs. the original image, small size      │\n",
       "│                            │            │ ratio gives smaller file size.                                        │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               image_output │ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> If set, then output will be saved as images. This         │\n",
       "│                            │            │ includes intermediate, final results in the form of PNG and GIF. If   │\n",
       "│                            │            │ set to <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, then no images will be saved, everything will be saved  │\n",
       "│                            │            │ in a Protobuf LZ4 format.                                             │\n",
       "│                            │            │ <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docarray.jina.ai/fundamentals/documentarray/serialization/#f…</span> │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 init_image │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ Recall that in the image sequence above, the first image shown is     │\n",
       "│                            │            │ just noise.  If an init_image is provided, diffusion will replace the │\n",
       "│                            │            │ noise with the init_image as its starting state.  To use an           │\n",
       "│                            │            │ init_image, upload the image to the Colab instance or your Google     │\n",
       "│                            │            │ Drive, and enter the full image path here.                            │\n",
       "│                            │            │ If using an init_image, you may need to increase skip_steps to ~ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>%  │\n",
       "│                            │            │ of total steps to retain the character of the init. See skip_steps    │\n",
       "│                            │            │ above for further discussion.                                         │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 init_scale │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>       │ This controls how strongly CLIP will try to match the init_image      │\n",
       "│                            │            │ provided.  This is balanced against the clip_guidance_scale <span style=\"font-weight: bold\">(</span>CGS<span style=\"font-weight: bold\">)</span>     │\n",
       "│                            │            │ above.  Too much init scale, and the image won’t change much during   │\n",
       "│                            │            │ diffusion. Too much CGS and the init image will be lost.              │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  n_batches │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>          │ This variable sets the number of still images you want DD to create.  │\n",
       "│                            │            │ If you are using an animation mode <span style=\"font-weight: bold\">(</span>see below for details<span style=\"font-weight: bold\">)</span> DD will    │\n",
       "│                            │            │ ignore n_batches and create a single set of animated frames based on  │\n",
       "│                            │            │ the animation settings.                                               │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│              name_docarray │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> When specified, it overrides the default naming schema o… │\n",
       "│                            │            │ the resulted DocumentArray. Useful when you have to know the result   │\n",
       "│                            │            │ DocumentArray name in advance.                                        │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ The name also supports variable substitution via `<span style=\"font-weight: bold\">{}</span>`. For example,   │\n",
       "│                            │            │ `<span style=\"color: #808000; text-decoration-color: #808000\">name_docarray</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'test-{steps}-{perlin_init}'</span>` will give the name of    │\n",
       "│                            │            │ the DocumentArray as `test-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span>-<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>`. Any variable in the config can │\n",
       "│                            │            │ be substituted.                                                       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        on_misspelled_token │ ignore     │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Strategy when encounter misspelled token, can be <span style=\"color: #008000; text-decoration-color: #008000\">'raise'</span>… │\n",
       "│                            │            │ <span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span> and <span style=\"color: #008000; text-decoration-color: #008000\">'ignore'</span>. If <span style=\"color: #008000; text-decoration-color: #008000\">'raise'</span>, then the misspelled token in the  │\n",
       "│                            │            │ prompt will raise a ValueError. If <span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>, then the token will be  │\n",
       "│                            │            │ replaced with the correct token. If <span style=\"color: #008000; text-decoration-color: #008000\">'ignore'</span>, then the token will be  │\n",
       "│                            │            │ ignored but a warning will show.                                      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                perlin_init │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ Normally, DD will use an image filled with random noise as a starting │\n",
       "│                            │            │ point for the diffusion curve.  If perlin_init is selected, DD will   │\n",
       "│                            │            │ instead use a Perlin noise model as an initial state.  Perlin has     │\n",
       "│                            │            │ very interesting characteristics, distinct from random noise, so it’s │\n",
       "│                            │            │ worth experimenting with this for your projects. Beyond perlin, you   │\n",
       "│                            │            │ can, of course, generate your own noise images <span style=\"font-weight: bold\">(</span>such as with GIMP,    │\n",
       "│                            │            │ etc<span style=\"font-weight: bold\">)</span> and use them as an init_image <span style=\"font-weight: bold\">(</span>without skipping steps<span style=\"font-weight: bold\">)</span>.          │\n",
       "│                            │            │ Choosing perlin_init does not affect the actual diffusion process,    │\n",
       "│                            │            │ just the starting point for the diffusion. Please note that selecting │\n",
       "│                            │            │ a perlin_init will replace and override any init_image you may have   │\n",
       "│                            │            │ specified.  Further, because the 2D, 3D and video animation systems   │\n",
       "│                            │            │ all rely on the init_image system, if you enable Perlin while using   │\n",
       "│                            │            │ animation modes, the perlin_init will jump in front of any previous   │\n",
       "│                            │            │ image or video input, and DD will NOT give you the expected sequence  │\n",
       "│                            │            │ of coherent images. All of that said, using Perlin and animation      │\n",
       "│                            │            │ modes together do make a very colorful rainbow effect, which can be   │\n",
       "│                            │            │ used creatively.                                                      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                perlin_mode │ mixed      │ sets type of Perlin noise: colored, gray, or a mix of both, giving    │\n",
       "│                            │            │ you additional options for noise types. Experiment to see what these  │\n",
       "│                            │            │ do in your projects.                                                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                   rand_mag │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>       │ Affects only the fuzzy_prompt.  Controls the magnitude of the random  │\n",
       "│                            │            │ noise added by fuzzy_prompt.                                          │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│            randomize_class │ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>       │ Controls whether the imagenet class is randomly changed each          │\n",
       "│                            │            │ iteration                                                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                range_scale │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span>        │ Optional, set to zero to turn off.  Used for adjustment of color      │\n",
       "│                            │            │ contrast.  Lower range_scale will increase contrast. Very low numbers │\n",
       "│                            │            │ create a reduced color palette, resulting in more vibrant or          │\n",
       "│                            │            │ poster-like images. Higher range_scale will reduce contrast, for more │\n",
       "│                            │            │ muted images.                                                         │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  sat_scale │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>          │ Saturation scale. Optional, set to zero to turn off.  If used,        │\n",
       "│                            │            │ sat_scale will help mitigate oversaturation. If your image is too     │\n",
       "│                            │            │ saturated, increase sat_scale to reduce the saturation.               │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  save_rate │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>         │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> The number of steps to save intermediate results. It is … │\n",
       "│                            │            │ replacement to original `display_rate` parameter. Set it to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span> for    │\n",
       "│                            │            │ not saving any intermediate result.                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                       seed │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ Deep in the diffusion code, there is a random number ‘seed’ which is  │\n",
       "│                            │            │ used as the basis for determining the initial state of the diffusion. │\n",
       "│                            │            │ By default, this is random, but you can also specify your own seed.   │\n",
       "│                            │            │ This is useful if you like a particular result and would like to run  │\n",
       "│                            │            │ more iterations that will be similar.                                 │\n",
       "│                            │            │ After each run, the actual seed value used will be reported in the    │\n",
       "│                            │            │ parameters report, and can be reused if desired by entering seed #    │\n",
       "│                            │            │ here.  If a specific numerical seed is used repeatedly, the resulting │\n",
       "│                            │            │ images will be quite similar but not identical.                       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 skip_event │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> A multiprocessing/asyncio/threading.Event that once set,  │\n",
       "│                            │            │ will skip the current run and move to the next run as defined in      │\n",
       "│                            │            │ `n_batches`.                                                          │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 skip_steps │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>          │ Consider the chart shown here.  Noise scheduling <span style=\"font-weight: bold\">(</span>denoise strength<span style=\"font-weight: bold\">)</span>   │\n",
       "│                            │            │ starts very high and progressively gets lower and lower as diffusion  │\n",
       "│                            │            │ steps progress. The noise levels in the first few steps are very      │\n",
       "│                            │            │ high, so images change dramatically in early steps.                   │\n",
       "│                            │            │ As DD moves along the curve, noise levels <span style=\"font-weight: bold\">(</span>and thus the amount an     │\n",
       "│                            │            │ image changes per step<span style=\"font-weight: bold\">)</span> declines, and image coherence from one step   │\n",
       "│                            │            │ to the next increases.                                                │\n",
       "│                            │            │ The first few steps of denoising are often so dramatic that some      │\n",
       "│                            │            │ steps <span style=\"font-weight: bold\">(</span>maybe <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>% of total<span style=\"font-weight: bold\">)</span> can be skipped without affecting the    │\n",
       "│                            │            │ final image. You can experiment with this as a way to cut render      │\n",
       "│                            │            │ times.                                                                │\n",
       "│                            │            │ If you skip too many steps, however, the remaining noise may not be   │\n",
       "│                            │            │ high enough to generate new content, and thus may not have ‘time      │\n",
       "│                            │            │ left’ to finish an image satisfactorily.                              │\n",
       "│                            │            │ Also, depending on your other settings, you may need to skip steps to │\n",
       "│                            │            │ prevent CLIP from overshooting your goal, resulting in ‘blown out’    │\n",
       "│                            │            │ colors <span style=\"font-weight: bold\">(</span>hyper saturated, solid white, or solid black regions<span style=\"font-weight: bold\">)</span> or      │\n",
       "│                            │            │ otherwise poor image quality.  Consider that the denoising process is │\n",
       "│                            │            │ at its strongest in the early steps, so skipping steps can sometimes  │\n",
       "│                            │            │ mitigate other problems.                                              │\n",
       "│                            │            │ Lastly, if using an init_image, you will need to skip ~<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>% of the     │\n",
       "│                            │            │ diffusion steps to retain the shapes in the original init image.      │\n",
       "│                            │            │ However, if you’re using an init_image, you can also adjust           │\n",
       "│                            │            │ skip_steps up or down for creative reasons.  With low skip_steps you  │\n",
       "│                            │            │ can get a result <span style=\"color: #008000; text-decoration-color: #008000\">\"inspired by\"</span> the init_image which will retain the   │\n",
       "│                            │            │ colors and rough layout and shapes but look quite different. With     │\n",
       "│                            │            │ high skip_steps you can preserve most of the init_image contents and  │\n",
       "│                            │            │ just do fine tuning of the texture.                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                      steps │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span>        │ When creating an image, the denoising curve is subdivided into steps  │\n",
       "│                            │            │ for processing. Each step <span style=\"font-weight: bold\">(</span>or iteration<span style=\"font-weight: bold\">)</span> involves the AI looking at   │\n",
       "│                            │            │ subsets of the image called ‘cuts’ and calculating the ‘direction’    │\n",
       "│                            │            │ the image should be guided to be more like the prompt. Then it        │\n",
       "│                            │            │ adjusts the image with the help of the diffusion denoiser, and moves  │\n",
       "│                            │            │ to the next step.                                                     │\n",
       "│                            │            │ Increasing steps will provide more opportunities for the AI to adjust │\n",
       "│                            │            │ the image, and each adjustment will be smaller, and thus will yield a │\n",
       "│                            │            │ more precise, detailed image.  Increasing steps comes at the expense  │\n",
       "│                            │            │ of longer render times.  Also, while increasing steps should          │\n",
       "│                            │            │ generally increase image quality, there is a diminishing return on    │\n",
       "│                            │            │ additional steps beyond <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> steps.  However, some intricate     │\n",
       "│                            │            │ images can take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>, or more steps.  It is really up to the    │\n",
       "│                            │            │ user.                                                                 │\n",
       "│                            │            │ Just know that the render time is directly related to the number of   │\n",
       "│                            │            │ steps, and many other parameters have a major impact on image         │\n",
       "│                            │            │ quality, without costing additional time.                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 stop_event │ <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>       │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> A multiprocessing/asyncio/threading.Event that once set,  │\n",
       "│                            │            │ will stop all generation of `n_batches` and immediately return from   │\n",
       "│                            │            │ `create`.                                                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│           text_clip_on_cpu │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Place text transformers of CLIP models on CPU. This save… │\n",
       "│                            │            │ more VRAM and will not hurt the speed at all on T4, P100, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3090</span>;       │\n",
       "│                            │            │ however, there are few community members report issue on V100 when it │\n",
       "│                            │            │ is `<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>`.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               text_prompts │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'A </span>       │ Phrase, sentence, or string of words and phrases describing what the  │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">beautiful </span> │ image should look like.  The words will be analyzed by the AI and     │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">painting </span>  │ will guide the diffusion process toward the <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">image</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> you describe.    │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">of a </span>      │ These can include commas and weights to adjust the relative           │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">singular </span>  │ importance of each element.  E.g. <span style=\"color: #008000; text-decoration-color: #008000\">\"A beautiful painting of a singular</span> │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">lighthouse</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">lighthouse, shining its light across a tumultuous sea of blood by </span>    │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">, shining </span> │ <span style=\"color: #008000; text-decoration-color: #008000\">greg rutkowski and thomas kinkade, Trending on artstation.\"</span>           │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">its light </span> │ Notice that this prompt loosely follows a structure: , , , ; this is  │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">across a </span>  │ a good starting point for your experiments.                           │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">tumultuous</span> │ Developing text prompts takes practice and experience, and is not the │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">sea of </span>    │ subject of this guide.  If you are a beginner to writing text         │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">blood by </span>  │ prompts, a good place to start is on a simple AI art app like Night   │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">greg </span>      │ Cafe, starry ai or WOMBO prior to using DD, to get a feel for how     │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">rutkowski </span> │ text gets translated into images by GAN tools.  These other apps use  │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">and thomas</span> │ different technologies, but many of the same principles apply.        │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">kinkade, </span>  │                                                                       │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">Trending </span>  │ You can add weight at the end of each prompt string, say `:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>` for    │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">on </span>        │ positive weights and `:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3</span>` for negative weights.                      │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">artstation</span> │                                                                       │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">.'</span>,        │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Unlike original DD notebook, `text_prompts` does not nee… │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">'yellow </span>   │ to be indexed by the timestamp. It is a list of strings.              │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">color </span>     │                                                                       │\n",
       "│                            │ <span style=\"color: #008000; text-decoration-color: #008000\">scheme'</span><span style=\"font-weight: bold\">]</span>   │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│     transformation_percent │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.09</span><span style=\"font-weight: bold\">]</span>     │ Steps expressed in percentages in which the symmetry is enforced      │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│ truncate_overlength_prompt │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> all CLIP models use <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span> as the context length. Set this    │\n",
       "│                            │            │ parameter truncates the prompt to the length of the model's context   │\n",
       "│                            │            │ length.                                                               │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                   tv_scale │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>          │ Total variance denoising. Optional, set to zero to turn off. Controls │\n",
       "│                            │            │ ‘smoothness’ of final output. If used, tv_scale will try to smooth    │\n",
       "│                            │            │ out your final image to reduce overall noise. If your image is too    │\n",
       "│                            │            │ ‘crunchy’, increase tv_scale. TV denoising is good at preserving      │\n",
       "│                            │            │ edges while smoothing away noise in flat regions.  See                │\n",
       "│                            │            │ <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://en.wikipedia.org/wiki/Total_variation_denoising</span>               │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> Can be scheduled via syntax `*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>+*<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│    use_horizontal_symmetry │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ Enforce symmetry over y axis of the image on  steps of the diffusion  │\n",
       "│                            │            │ process                                                               │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        use_secondary_model │ <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>       │ Option to use a secondary purpose-made diffusion model to clean up    │\n",
       "│                            │            │ interim diffusion images for CLIP evaluation.    If this option is    │\n",
       "│                            │            │ turned off, DD will use the regular <span style=\"font-weight: bold\">(</span>large<span style=\"font-weight: bold\">)</span> diffusion model.    Using │\n",
       "│                            │            │ the secondary model is faster - one user reported a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>% improvement   │\n",
       "│                            │            │ in render speed! However, the secondary model is much smaller, and    │\n",
       "│                            │            │ may reduce image quality and detail.  I suggest you experiment with   │\n",
       "│                            │            │ this.                                                                 │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> It can be also an boolean list schedule that represents   │\n",
       "│                            │            │ on/off on secondary model at each step, same as                       │\n",
       "│                            │            │ `clip_models_schedules` or `cut_overview`.                            │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ Note that without secondary model it will consume higher VRAM but     │\n",
       "│                            │            │ gives better quality. Simply put, secondary model is faster, but a    │\n",
       "│                            │            │ less accurate approximation to `p_mean_variance`.                     │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│      use_vertical_symmetry │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ Enforce symmetry over x axis of the image on  steps of the diffusion  │\n",
       "│                            │            │ process                                                               │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│             visualize_cuts │ <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>      │ <span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000; font-weight: bold\">🆕 DiscoArt</span> If set, then `cuts-<span style=\"font-weight: bold\">{</span>step<span style=\"font-weight: bold\">}</span>.png` will be saved for each     │\n",
       "│                            │            │ step, visualizing all cuts in a sprite image at each step.            │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               width_height │ <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280</span>,     │ Desired final image size, in pixels. You can have a square, wide, or  │\n",
       "│                            │ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768</span><span style=\"font-weight: bold\">]</span>       │ tall image, but each edge length should be set to a multiple of 64px, │\n",
       "│                            │            │ and a minimum of 512px on the default CLIP model setting.  If you     │\n",
       "│                            │            │ forget to use multiples of 64px in your dimensions, DD will adjust    │\n",
       "│                            │            │ the dimensions of your image to make it so.                           │\n",
       "│                            │            │                                                                       │\n",
       "╰────────────────────────────┴────────────┴───────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Cheatsheet for all supported parameters                                      \u001b[0m\n",
       "╭────────────────────────────┬────────────┬───────────────────────────────────────────────────────────────────────╮\n",
       "│\u001b[1m \u001b[0m\u001b[1m                  Argument\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mDefault   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mDescription                                                          \u001b[0m\u001b[1m \u001b[0m│\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 batch_name │ \u001b[3;35mNone\u001b[0m       │ The name of the batch, the batch id will be named as \u001b[32m\"discoart-\u001b[0m\u001b[32m-\u001b[0m\u001b[32m\"\u001b[0m. To │\n",
       "│                            │            │ avoid your artworks be overridden by other users, please use a unique │\n",
       "│                            │            │ name.                                                                 │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 batch_size │ \u001b[1;36m1\u001b[0m          │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The number of samples generated at each steps. Say        │\n",
       "│                            │            │ `\u001b[33mbatch_size\u001b[0m=\u001b[1;36m3\u001b[0m`, then you can generate three images in one run. Not    │\n",
       "│                            │            │ only this is faster than three runs, but it leverages loss function   │\n",
       "│                            │            │ better and potentially yields higher quality images.                  │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ One can of course also do `\u001b[33mn_batches\u001b[0m=\u001b[1;36m3\u001b[0m` and `\u001b[33mbatch_size\u001b[0m=\u001b[1;36m1\u001b[0m` to         │\n",
       "│                            │            │ generate three images in one run. But using `\u001b[33mbatch_size\u001b[0m=\u001b[1;36m3\u001b[0m` is         │\n",
       "│                            │            │ marginally faster and yield higher quality images.                    │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ High `batch_size` can lead to OOM.                                    │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 clamp_grad │ \u001b[3;92mTrue\u001b[0m       │ As I understand it, clamp_grad is an internal limiter that stops DD   │\n",
       "│                            │            │ from producing extreme results.  Try your images with and without     │\n",
       "│                            │            │ clamp_grad. If the image changes drastically with clamp_grad turned   │\n",
       "│                            │            │ off, it probably means your clip_guidance_scale is too high and       │\n",
       "│                            │            │ should be reduced.                                                    │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  clamp_max │ \u001b[1;36m0.05\u001b[0m       │ Sets the value of the clamp_grad limitation. Default is \u001b[1;36m0.05\u001b[0m,         │\n",
       "│                            │            │ providing for smoother, more muted coloration in images, but setting  │\n",
       "│                            │            │ higher values \u001b[1m(\u001b[0m\u001b[1;36m0.15\u001b[0m-\u001b[1;36m0.3\u001b[0m\u001b[1m)\u001b[0m can provide interesting contrast and         │\n",
       "│                            │            │ vibrancy.                                                             │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│              clip_denoised │ \u001b[3;91mFalse\u001b[0m      │ Determines whether CLIP discriminates a noisy or denoised image       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        clip_guidance_scale │ \u001b[1;36m5000\u001b[0m       │ CGS is one of the most important parameters you will use. It tells DD │\n",
       "│                            │            │ how strongly you want CLIP to move toward your prompt each timestep.  │\n",
       "│                            │            │ Higher is generally better, but if CGS is too strong it will          │\n",
       "│                            │            │ overshoot the goal and distort the image. So a happy medium is        │\n",
       "│                            │            │ needed, and it takes experience to learn how to adjust CGS.           │\n",
       "│                            │            │ Note that this parameter generally scales with image dimensions. In   │\n",
       "│                            │            │ other words, if you increase your total dimensions by \u001b[1;36m50\u001b[0m% \u001b[1m(\u001b[0me.g. a     │\n",
       "│                            │            │ change from \u001b[1;36m512\u001b[0m x \u001b[1;36m512\u001b[0m to \u001b[1;36m512\u001b[0m x \u001b[1;36m768\u001b[0m\u001b[1m)\u001b[0m, then to maintain the same effect │\n",
       "│                            │            │ on the image, you’d want to increase clip_guidance_scale from \u001b[1;36m5000\u001b[0m to │\n",
       "│                            │            │ \u001b[1;36m7500\u001b[0m.                                                                 │\n",
       "│                            │            │ Of the basic settings, clip_guidance_scale, steps and skip_steps are  │\n",
       "│                            │            │ the most important contributors to image quality, so learn them well. │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                clip_models │ \u001b[1m[\u001b[0m\u001b[32m'ViT-B-32\u001b[0m │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m CLIP Model selectors provided by open-clip package.       │\n",
       "│                            │ \u001b[32m::openai'\u001b[0m, │                                                                       │\n",
       "│                            │            │ These various CLIP models are available for you to use during image   │\n",
       "│                            │ \u001b[32m'ViT-B-16:\u001b[0m │ generation.  Models have different styles or ‘flavors,’ so look       │\n",
       "│                            │ \u001b[32m:openai'\u001b[0m,  │ around.                                                               │\n",
       "│                            │ \u001b[32m'RN50::ope\u001b[0m │ You can mix in multiple models as well for different results.         │\n",
       "│                            │ \u001b[32mnai'\u001b[0m\u001b[1m]\u001b[0m      │ However, keep in mind that some models are extremely memory-hungry,   │\n",
       "│                            │            │ and turning on additional models will take additional memory and may  │\n",
       "│                            │            │ cause a crash.                                                        │\n",
       "│                            │            │ Also supported open_clip pretrained models, use `::` to separate      │\n",
       "│                            │            │ model name and pretrained weight name, e.g. `ViT-B/\u001b[1;36m32\u001b[0m::laion2b_e16`.  │\n",
       "│                            │            │ Full list of models and weights can be found here:                    │\n",
       "│                            │            │ \u001b[4;94mhttps://github.com/mlfoundations/open_clip#pretrained-model-interface\u001b[0m │\n",
       "│                            │            │  RN50::openai                                                         │\n",
       "│                            │            │  RN50::yfcc15m                                                        │\n",
       "│                            │            │  RN\u001b[1;92m50::cc12\u001b[0mm                                                          │\n",
       "│                            │            │  RN50-quickgelu::openai                                               │\n",
       "│                            │            │  RN50-quickgelu::yfcc15m                                              │\n",
       "│                            │            │  RN50-quickgelu::cc12m                                                │\n",
       "│                            │            │  RN101::openai                                                        │\n",
       "│                            │            │  RN101::yfcc15m                                                       │\n",
       "│                            │            │  RN101-quickgelu::openai                                              │\n",
       "│                            │            │  RN101-quickgelu::yfcc15m                                             │\n",
       "│                            │            │  RN5\u001b[1;36m0x4\u001b[0m::openai                                                       │\n",
       "│                            │            │  RN5\u001b[1;36m0x16\u001b[0m::openai                                                      │\n",
       "│                            │            │  RN5\u001b[1;36m0x64\u001b[0m::openai                                                      │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m::openai                                                     │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m::laion2b_e16                                                │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m::laion400m_e31                                              │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m::laion400m_e32                                              │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m-quickgelu::openai                                           │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m-quickgelu::laion400m_e31                                    │\n",
       "│                            │            │  ViT-B-\u001b[1;36m32\u001b[0m-quickgelu::laion400m_e32                                    │\n",
       "│                            │            │  ViT-B-\u001b[1;36m16\u001b[0m::openai                                                     │\n",
       "│                            │            │  ViT-B-\u001b[1;36m16\u001b[0m::laion400m_e31                                              │\n",
       "│                            │            │  ViT-B-\u001b[1;36m16\u001b[0m::laion400m_e32                                              │\n",
       "│                            │            │  ViT-B-\u001b[1;36m16\u001b[0m-plus-\u001b[1;36m240\u001b[0m::laion400m_e31                                     │\n",
       "│                            │            │  ViT-B-\u001b[1;36m16\u001b[0m-plus-\u001b[1;36m240\u001b[0m::laion400m_e32                                     │\n",
       "│                            │            │  ViT-L-\u001b[1;36m14\u001b[0m::openai                                                     │\n",
       "│                            │            │  ViT-L-\u001b[1;36m14\u001b[0m-\u001b[1;36m336\u001b[0m::openai                                                 │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│      clip_models_schedules │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m A dictionary of string to boolean list that represents    │\n",
       "│                            │            │ on/off of CLIP models at each step. CLIP Model schedules use a        │\n",
       "│                            │            │ similar mechanism to cut_overview and `cut_innercut`. For example,    │\n",
       "│                            │            │ `\u001b[1m{\u001b[0m\u001b[32m\"RN101::openai\"\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mTrue\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*400+\u001b[0m\u001b[32m[\u001b[0m\u001b[32mFalse\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*600\"\u001b[0m\u001b[1m}\u001b[0m` schedules RN101 to run  │\n",
       "│                            │            │ for the first \u001b[1;36m40\u001b[0m% of steps and then is no longer used for the         │\n",
       "│                            │            │ remaining steps. `\u001b[1m[\u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m1000\u001b[0m` is equivalent to always on and is the  │\n",
       "│                            │            │ default if this parameter is not set. Note, the model must be         │\n",
       "│                            │            │ included in the `clip_models` otherwise this parameter is ignored.    │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 cut_ic_pow │ \u001b[1;36m1.0\u001b[0m        │ This sets the size of the border used for inner cuts.  High           │\n",
       "│                            │            │ cut_ic_pow values have larger borders, and therefore the cuts         │\n",
       "│                            │            │ themselves will be smaller and provide finer details.  If you have    │\n",
       "│                            │            │ too many or too-small inner cuts, you may lose overall image          │\n",
       "│                            │            │ coherency and/or it may cause an undesirable ‘mosaic’ effect.   Low   │\n",
       "│                            │            │ cut_ic_pow values will allow the inner cuts to be larger, helping     │\n",
       "│                            │            │ image coherency while still helping with some details.                │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m This can be a list of floats that represents the value a… │\n",
       "│                            │            │ different steps, the syntax follows the same as `cut_overview`.       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_icgray_p │ \u001b[1m[\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m400\u001b[0m+ │ In addition to the overall cut schedule, a portion of the cuts can be │\n",
       "│                            │ \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m600\u001b[0m    │ set to be grayscale instead of color. This may help with improved     │\n",
       "│                            │            │ definition of shapes and edges, especially in the early diffusion     │\n",
       "│                            │            │ steps where the image structure is being defined.                     │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_innercut │ \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m400\u001b[0m+\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m │ The schedule of inner cuts, which are smaller cropped images from the │\n",
       "│                            │ \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m600\u001b[0m     │ interior of the image, helpful in tuning fine details. The size of    │\n",
       "│                            │            │ the inner cuts can be adjusted using the `cut_ic_pow` parameter.      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cut_overview │ \u001b[1m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m400\u001b[0m+\u001b[1m[\u001b[0m │ The schedule of overview cuts, which take a snapshot of the entire    │\n",
       "│                            │ \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m*\u001b[1;36m600\u001b[0m     │ image and evaluate that against the prompt.                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        cut_schedules_group │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The group name of the cut-scheduling. For example,        │\n",
       "│                            │            │ `default` corresponds to                                              │\n",
       "│                            │            │ default:                                                              │\n",
       "│                            │            │   cut_overview: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*400+\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*600\"\u001b[0m                                    │\n",
       "│                            │            │   cut_innercut: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m4\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*400+\u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*600\"\u001b[0m                                    │\n",
       "│                            │            │   cut_ic_pow: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*1000\"\u001b[0m                                              │\n",
       "│                            │            │   cut_icgray_p: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m0.2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*400+\u001b[0m\u001b[32m[\u001b[0m\u001b[32m0\u001b[0m\u001b[32m]\u001b[0m\u001b[32m*600\"\u001b[0m                                   │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ There are \u001b[1;36m2\u001b[0m predefined groups: `pad_or_pulp` and `watercolor`.        │\n",
       "│                            │            │ This parameter has less priority than the cut_overview, cut_innercut, │\n",
       "│                            │            │ cut_ic_pow, cut_icgray_p parameters, meaning that one can override    │\n",
       "│                            │            │ cut_overview, cut_innercut, cut_ic_pow, cut_icgray_p by setting them  │\n",
       "│                            │            │ afterwards.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               cutn_batches │ \u001b[1;36m4\u001b[0m          │ Each iteration, the AI cuts the image into smaller pieces known as    │\n",
       "│                            │            │ cuts, and compares each cut to the prompt to decide how to guide the  │\n",
       "│                            │            │ next diffusion step.  More cuts can generally lead to better images,  │\n",
       "│                            │            │ since DD has more chances to fine-tune the image precision in each    │\n",
       "│                            │            │ timestep.                                                             │\n",
       "│                            │            │ Additional cuts are memory intensive, however, and if DD tries to     │\n",
       "│                            │            │ evaluate too many cuts at once, it can run out of memory.  You can    │\n",
       "│                            │            │ use cutn_batches to increase cuts per timestep without increasing     │\n",
       "│                            │            │ memory usage.                                                         │\n",
       "│                            │            │ At the default settings, DD is scheduled to do \u001b[1;36m16\u001b[0m cuts per timestep.  │\n",
       "│                            │            │ If cutn_batches is set to \u001b[1;36m1\u001b[0m, there will indeed only be \u001b[1;36m16\u001b[0m cuts total  │\n",
       "│                            │            │ per timestep.                                                         │\n",
       "│                            │            │ However, if cutn_batches is increased to \u001b[1;36m4\u001b[0m, DD will do \u001b[1;36m64\u001b[0m cuts total  │\n",
       "│                            │            │ in each timestep, divided into \u001b[1;36m4\u001b[0m sequential batches of \u001b[1;36m16\u001b[0m cuts each.  │\n",
       "│                            │            │ Because the cuts are being evaluated only \u001b[1;36m16\u001b[0m at a time, DD uses the   │\n",
       "│                            │            │ memory required for only \u001b[1;36m16\u001b[0m cuts, but gives you the quality benefit   │\n",
       "│                            │            │ of \u001b[1;36m64\u001b[0m cuts.  The tradeoff, of course, is that this will take ~\u001b[1;36m4\u001b[0m times │\n",
       "│                            │            │ as long to render each image.                                         │\n",
       "│                            │            │ So, \u001b[1m(\u001b[0mscheduled cuts\u001b[1m)\u001b[0m x \u001b[1m(\u001b[0mcutn_batches\u001b[1m)\u001b[0m = \u001b[1m(\u001b[0mtotal cuts per timestep\u001b[1m)\u001b[0m.    │\n",
       "│                            │            │ Increasing cutn_batches will increase render times, however, as the   │\n",
       "│                            │            │ work is being done sequentially.  DD’s default cut schedule is a good │\n",
       "│                            │            │ place to start, but the cut schedule can be adjusted in the Cutn      │\n",
       "│                            │            │ Scheduling section, explained below.                                  │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│            diffusion_model │ 512x512_di │ Diffusion_model of choice. Note that you don't have to write the full │\n",
       "│                            │ ffusion_un │ name of the diffusion model, e.g. any prefix is enough.               │\n",
       "│                            │ cond_finet │                                                                       │\n",
       "│                            │ une_008100 │ To use a listed all diffusion models, you can do:                     │\n",
       "│                            │            │ ```python                                                             │\n",
       "│                            │            │ from discoart import create                                           │\n",
       "│                            │            │ \u001b[1;35mcreate\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdiffusion_model\u001b[0m=\u001b[32m'portrait_generator'\u001b[0m, \u001b[33m...\u001b[0m\u001b[1m)\u001b[0m                     │\n",
       "│                            │            │ ```                                                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│     diffusion_model_config │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The customized diffusion model config as a dictionary, i… │\n",
       "│                            │            │ specified will override the values with the same name in the default  │\n",
       "│                            │            │ model config.                                                         │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│    diffusion_sampling_mode │ ddim       │ Two alternate diffusion denoising algorithms. ddim has been around    │\n",
       "│                            │            │ longer, and is more established and tested.  plms is a newly added    │\n",
       "│                            │            │ alternate method that promises good diffusion results in fewer steps, │\n",
       "│                            │            │ but has not been as fully tested and may have side effects. This new  │\n",
       "│                            │            │ plms mode is actively being researched in the                         │\n",
       "│                            │            │ #settings-and-techniques channel in the DD Discord.                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               display_rate │ \u001b[1;36m1\u001b[0m          │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The refresh rate of displaying the generated images in    │\n",
       "│                            │            │ Notebook environment. The value has nothing to do with the rate of    │\n",
       "│                            │            │ saving images and the speed of generation or sampling. It is purely   │\n",
       "│                            │            │ about your browser refreshing. Smaller value \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m is the smallest, \u001b[1;36m0\u001b[0m    │\n",
       "│                            │            │ will disable the refresh\u001b[1m)\u001b[0m will consume more network bandwidth, as     │\n",
       "│                            │            │ your browser will actively fetch refreshed images to local. Change it │\n",
       "│                            │            │ to a bigger value if you have limited network bandwidth.              │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                        eta │ \u001b[1;36m0.8\u001b[0m        │ eta \u001b[1m(\u001b[0mgreek letter η\u001b[1m)\u001b[0m is a diffusion model variable that mixes in a    │\n",
       "│                            │            │ random amount of scaled noise into each timestep. \u001b[1;36m0\u001b[0m is no noise, \u001b[1;36m1.0\u001b[0m  │\n",
       "│                            │            │ is more noise. As with most DD parameters, you can go below zero for  │\n",
       "│                            │            │ eta, but it may give you unpredictable results.                       │\n",
       "│                            │            │ The steps parameter has a close relationship with the eta parameter.  │\n",
       "│                            │            │ If you set eta to \u001b[1;36m0\u001b[0m, then you can get decent output with only \u001b[1;36m50\u001b[0m-\u001b[1;36m75\u001b[0m   │\n",
       "│                            │            │ steps. Setting eta to \u001b[1;36m1.0\u001b[0m favors higher step counts, ideally around   │\n",
       "│                            │            │ \u001b[1;36m250\u001b[0m and up. eta has a subtle, unpredictable effect on image, so       │\n",
       "│                            │            │ you’ll need to experiment to see how this affects your projects.      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                    gif_fps │ \u001b[1;36m20\u001b[0m         │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The frame rate of the generated GIF. Set it to \u001b[1;36m-1\u001b[0m for no… │\n",
       "│                            │            │ saving GIF.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│             gif_size_ratio │ \u001b[1;36m0.5\u001b[0m        │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The relative size vs. the original image, small size      │\n",
       "│                            │            │ ratio gives smaller file size.                                        │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               image_output │ \u001b[3;92mTrue\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m If set, then output will be saved as images. This         │\n",
       "│                            │            │ includes intermediate, final results in the form of PNG and GIF. If   │\n",
       "│                            │            │ set to \u001b[3;91mFalse\u001b[0m, then no images will be saved, everything will be saved  │\n",
       "│                            │            │ in a Protobuf LZ4 format.                                             │\n",
       "│                            │            │ \u001b[4;94mhttps://docarray.jina.ai/fundamentals/documentarray/serialization/#f…\u001b[0m │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 init_image │ \u001b[3;35mNone\u001b[0m       │ Recall that in the image sequence above, the first image shown is     │\n",
       "│                            │            │ just noise.  If an init_image is provided, diffusion will replace the │\n",
       "│                            │            │ noise with the init_image as its starting state.  To use an           │\n",
       "│                            │            │ init_image, upload the image to the Colab instance or your Google     │\n",
       "│                            │            │ Drive, and enter the full image path here.                            │\n",
       "│                            │            │ If using an init_image, you may need to increase skip_steps to ~ \u001b[1;36m50\u001b[0m%  │\n",
       "│                            │            │ of total steps to retain the character of the init. See skip_steps    │\n",
       "│                            │            │ above for further discussion.                                         │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 init_scale │ \u001b[1;36m1000\u001b[0m       │ This controls how strongly CLIP will try to match the init_image      │\n",
       "│                            │            │ provided.  This is balanced against the clip_guidance_scale \u001b[1m(\u001b[0mCGS\u001b[1m)\u001b[0m     │\n",
       "│                            │            │ above.  Too much init scale, and the image won’t change much during   │\n",
       "│                            │            │ diffusion. Too much CGS and the init image will be lost.              │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  n_batches │ \u001b[1;36m4\u001b[0m          │ This variable sets the number of still images you want DD to create.  │\n",
       "│                            │            │ If you are using an animation mode \u001b[1m(\u001b[0msee below for details\u001b[1m)\u001b[0m DD will    │\n",
       "│                            │            │ ignore n_batches and create a single set of animated frames based on  │\n",
       "│                            │            │ the animation settings.                                               │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│              name_docarray │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m When specified, it overrides the default naming schema o… │\n",
       "│                            │            │ the resulted DocumentArray. Useful when you have to know the result   │\n",
       "│                            │            │ DocumentArray name in advance.                                        │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ The name also supports variable substitution via `\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m`. For example,   │\n",
       "│                            │            │ `\u001b[33mname_docarray\u001b[0m=\u001b[32m'test-\u001b[0m\u001b[32m{\u001b[0m\u001b[32msteps\u001b[0m\u001b[32m}\u001b[0m\u001b[32m-\u001b[0m\u001b[32m{\u001b[0m\u001b[32mperlin_init\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m` will give the name of    │\n",
       "│                            │            │ the DocumentArray as `test-\u001b[1;36m250\u001b[0m-\u001b[3;91mFalse\u001b[0m`. Any variable in the config can │\n",
       "│                            │            │ be substituted.                                                       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        on_misspelled_token │ ignore     │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Strategy when encounter misspelled token, can be \u001b[32m'raise'\u001b[0m… │\n",
       "│                            │            │ \u001b[32m'correct'\u001b[0m and \u001b[32m'ignore'\u001b[0m. If \u001b[32m'raise'\u001b[0m, then the misspelled token in the  │\n",
       "│                            │            │ prompt will raise a ValueError. If \u001b[32m'correct'\u001b[0m, then the token will be  │\n",
       "│                            │            │ replaced with the correct token. If \u001b[32m'ignore'\u001b[0m, then the token will be  │\n",
       "│                            │            │ ignored but a warning will show.                                      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                perlin_init │ \u001b[3;91mFalse\u001b[0m      │ Normally, DD will use an image filled with random noise as a starting │\n",
       "│                            │            │ point for the diffusion curve.  If perlin_init is selected, DD will   │\n",
       "│                            │            │ instead use a Perlin noise model as an initial state.  Perlin has     │\n",
       "│                            │            │ very interesting characteristics, distinct from random noise, so it’s │\n",
       "│                            │            │ worth experimenting with this for your projects. Beyond perlin, you   │\n",
       "│                            │            │ can, of course, generate your own noise images \u001b[1m(\u001b[0msuch as with GIMP,    │\n",
       "│                            │            │ etc\u001b[1m)\u001b[0m and use them as an init_image \u001b[1m(\u001b[0mwithout skipping steps\u001b[1m)\u001b[0m.          │\n",
       "│                            │            │ Choosing perlin_init does not affect the actual diffusion process,    │\n",
       "│                            │            │ just the starting point for the diffusion. Please note that selecting │\n",
       "│                            │            │ a perlin_init will replace and override any init_image you may have   │\n",
       "│                            │            │ specified.  Further, because the 2D, 3D and video animation systems   │\n",
       "│                            │            │ all rely on the init_image system, if you enable Perlin while using   │\n",
       "│                            │            │ animation modes, the perlin_init will jump in front of any previous   │\n",
       "│                            │            │ image or video input, and DD will NOT give you the expected sequence  │\n",
       "│                            │            │ of coherent images. All of that said, using Perlin and animation      │\n",
       "│                            │            │ modes together do make a very colorful rainbow effect, which can be   │\n",
       "│                            │            │ used creatively.                                                      │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                perlin_mode │ mixed      │ sets type of Perlin noise: colored, gray, or a mix of both, giving    │\n",
       "│                            │            │ you additional options for noise types. Experiment to see what these  │\n",
       "│                            │            │ do in your projects.                                                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                   rand_mag │ \u001b[1;36m0.05\u001b[0m       │ Affects only the fuzzy_prompt.  Controls the magnitude of the random  │\n",
       "│                            │            │ noise added by fuzzy_prompt.                                          │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│            randomize_class │ \u001b[3;92mTrue\u001b[0m       │ Controls whether the imagenet class is randomly changed each          │\n",
       "│                            │            │ iteration                                                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                range_scale │ \u001b[1;36m150\u001b[0m        │ Optional, set to zero to turn off.  Used for adjustment of color      │\n",
       "│                            │            │ contrast.  Lower range_scale will increase contrast. Very low numbers │\n",
       "│                            │            │ create a reduced color palette, resulting in more vibrant or          │\n",
       "│                            │            │ poster-like images. Higher range_scale will reduce contrast, for more │\n",
       "│                            │            │ muted images.                                                         │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  sat_scale │ \u001b[1;36m0\u001b[0m          │ Saturation scale. Optional, set to zero to turn off.  If used,        │\n",
       "│                            │            │ sat_scale will help mitigate oversaturation. If your image is too     │\n",
       "│                            │            │ saturated, increase sat_scale to reduce the saturation.               │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                  save_rate │ \u001b[1;36m20\u001b[0m         │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m The number of steps to save intermediate results. It is … │\n",
       "│                            │            │ replacement to original `display_rate` parameter. Set it to \u001b[1;36m-1\u001b[0m for    │\n",
       "│                            │            │ not saving any intermediate result.                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                       seed │ \u001b[3;35mNone\u001b[0m       │ Deep in the diffusion code, there is a random number ‘seed’ which is  │\n",
       "│                            │            │ used as the basis for determining the initial state of the diffusion. │\n",
       "│                            │            │ By default, this is random, but you can also specify your own seed.   │\n",
       "│                            │            │ This is useful if you like a particular result and would like to run  │\n",
       "│                            │            │ more iterations that will be similar.                                 │\n",
       "│                            │            │ After each run, the actual seed value used will be reported in the    │\n",
       "│                            │            │ parameters report, and can be reused if desired by entering seed #    │\n",
       "│                            │            │ here.  If a specific numerical seed is used repeatedly, the resulting │\n",
       "│                            │            │ images will be quite similar but not identical.                       │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 skip_event │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m A multiprocessing/asyncio/threading.Event that once set,  │\n",
       "│                            │            │ will skip the current run and move to the next run as defined in      │\n",
       "│                            │            │ `n_batches`.                                                          │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 skip_steps │ \u001b[1;36m0\u001b[0m          │ Consider the chart shown here.  Noise scheduling \u001b[1m(\u001b[0mdenoise strength\u001b[1m)\u001b[0m   │\n",
       "│                            │            │ starts very high and progressively gets lower and lower as diffusion  │\n",
       "│                            │            │ steps progress. The noise levels in the first few steps are very      │\n",
       "│                            │            │ high, so images change dramatically in early steps.                   │\n",
       "│                            │            │ As DD moves along the curve, noise levels \u001b[1m(\u001b[0mand thus the amount an     │\n",
       "│                            │            │ image changes per step\u001b[1m)\u001b[0m declines, and image coherence from one step   │\n",
       "│                            │            │ to the next increases.                                                │\n",
       "│                            │            │ The first few steps of denoising are often so dramatic that some      │\n",
       "│                            │            │ steps \u001b[1m(\u001b[0mmaybe \u001b[1;36m10\u001b[0m-\u001b[1;36m15\u001b[0m% of total\u001b[1m)\u001b[0m can be skipped without affecting the    │\n",
       "│                            │            │ final image. You can experiment with this as a way to cut render      │\n",
       "│                            │            │ times.                                                                │\n",
       "│                            │            │ If you skip too many steps, however, the remaining noise may not be   │\n",
       "│                            │            │ high enough to generate new content, and thus may not have ‘time      │\n",
       "│                            │            │ left’ to finish an image satisfactorily.                              │\n",
       "│                            │            │ Also, depending on your other settings, you may need to skip steps to │\n",
       "│                            │            │ prevent CLIP from overshooting your goal, resulting in ‘blown out’    │\n",
       "│                            │            │ colors \u001b[1m(\u001b[0mhyper saturated, solid white, or solid black regions\u001b[1m)\u001b[0m or      │\n",
       "│                            │            │ otherwise poor image quality.  Consider that the denoising process is │\n",
       "│                            │            │ at its strongest in the early steps, so skipping steps can sometimes  │\n",
       "│                            │            │ mitigate other problems.                                              │\n",
       "│                            │            │ Lastly, if using an init_image, you will need to skip ~\u001b[1;36m50\u001b[0m% of the     │\n",
       "│                            │            │ diffusion steps to retain the shapes in the original init image.      │\n",
       "│                            │            │ However, if you’re using an init_image, you can also adjust           │\n",
       "│                            │            │ skip_steps up or down for creative reasons.  With low skip_steps you  │\n",
       "│                            │            │ can get a result \u001b[32m\"inspired by\"\u001b[0m the init_image which will retain the   │\n",
       "│                            │            │ colors and rough layout and shapes but look quite different. With     │\n",
       "│                            │            │ high skip_steps you can preserve most of the init_image contents and  │\n",
       "│                            │            │ just do fine tuning of the texture.                                   │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                      steps │ \u001b[1;36m250\u001b[0m        │ When creating an image, the denoising curve is subdivided into steps  │\n",
       "│                            │            │ for processing. Each step \u001b[1m(\u001b[0mor iteration\u001b[1m)\u001b[0m involves the AI looking at   │\n",
       "│                            │            │ subsets of the image called ‘cuts’ and calculating the ‘direction’    │\n",
       "│                            │            │ the image should be guided to be more like the prompt. Then it        │\n",
       "│                            │            │ adjusts the image with the help of the diffusion denoiser, and moves  │\n",
       "│                            │            │ to the next step.                                                     │\n",
       "│                            │            │ Increasing steps will provide more opportunities for the AI to adjust │\n",
       "│                            │            │ the image, and each adjustment will be smaller, and thus will yield a │\n",
       "│                            │            │ more precise, detailed image.  Increasing steps comes at the expense  │\n",
       "│                            │            │ of longer render times.  Also, while increasing steps should          │\n",
       "│                            │            │ generally increase image quality, there is a diminishing return on    │\n",
       "│                            │            │ additional steps beyond \u001b[1;36m250\u001b[0m - \u001b[1;36m500\u001b[0m steps.  However, some intricate     │\n",
       "│                            │            │ images can take \u001b[1;36m1000\u001b[0m, \u001b[1;36m2000\u001b[0m, or more steps.  It is really up to the    │\n",
       "│                            │            │ user.                                                                 │\n",
       "│                            │            │ Just know that the render time is directly related to the number of   │\n",
       "│                            │            │ steps, and many other parameters have a major impact on image         │\n",
       "│                            │            │ quality, without costing additional time.                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                 stop_event │ \u001b[3;35mNone\u001b[0m       │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m A multiprocessing/asyncio/threading.Event that once set,  │\n",
       "│                            │            │ will stop all generation of `n_batches` and immediately return from   │\n",
       "│                            │            │ `create`.                                                             │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│           text_clip_on_cpu │ \u001b[3;91mFalse\u001b[0m      │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Place text transformers of CLIP models on CPU. This save… │\n",
       "│                            │            │ more VRAM and will not hurt the speed at all on T4, P100, \u001b[1;36m3090\u001b[0m;       │\n",
       "│                            │            │ however, there are few community members report issue on V100 when it │\n",
       "│                            │            │ is `\u001b[3;91mFalse\u001b[0m`.                                                           │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               text_prompts │ \u001b[1m[\u001b[0m\u001b[32m'A \u001b[0m       │ Phrase, sentence, or string of words and phrases describing what the  │\n",
       "│                            │ \u001b[32mbeautiful \u001b[0m │ image should look like.  The words will be analyzed by the AI and     │\n",
       "│                            │ \u001b[32mpainting \u001b[0m  │ will guide the diffusion process toward the \u001b[1;35mimage\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m you describe.    │\n",
       "│                            │ \u001b[32mof a \u001b[0m      │ These can include commas and weights to adjust the relative           │\n",
       "│                            │ \u001b[32msingular \u001b[0m  │ importance of each element.  E.g. \u001b[32m\"A beautiful painting of a singular\u001b[0m │\n",
       "│                            │ \u001b[32mlighthouse\u001b[0m │ \u001b[32mlighthouse, shining its light across a tumultuous sea of blood by \u001b[0m    │\n",
       "│                            │ \u001b[32m, shining \u001b[0m │ \u001b[32mgreg rutkowski and thomas kinkade, Trending on artstation.\"\u001b[0m           │\n",
       "│                            │ \u001b[32mits light \u001b[0m │ Notice that this prompt loosely follows a structure: , , , ; this is  │\n",
       "│                            │ \u001b[32macross a \u001b[0m  │ a good starting point for your experiments.                           │\n",
       "│                            │ \u001b[32mtumultuous\u001b[0m │ Developing text prompts takes practice and experience, and is not the │\n",
       "│                            │ \u001b[32msea of \u001b[0m    │ subject of this guide.  If you are a beginner to writing text         │\n",
       "│                            │ \u001b[32mblood by \u001b[0m  │ prompts, a good place to start is on a simple AI art app like Night   │\n",
       "│                            │ \u001b[32mgreg \u001b[0m      │ Cafe, starry ai or WOMBO prior to using DD, to get a feel for how     │\n",
       "│                            │ \u001b[32mrutkowski \u001b[0m │ text gets translated into images by GAN tools.  These other apps use  │\n",
       "│                            │ \u001b[32mand thomas\u001b[0m │ different technologies, but many of the same principles apply.        │\n",
       "│                            │ \u001b[32mkinkade, \u001b[0m  │                                                                       │\n",
       "│                            │ \u001b[32mTrending \u001b[0m  │ You can add weight at the end of each prompt string, say `:\u001b[1;36m10\u001b[0m` for    │\n",
       "│                            │ \u001b[32mon \u001b[0m        │ positive weights and `:\u001b[1;36m-3\u001b[0m` for negative weights.                      │\n",
       "│                            │ \u001b[32martstation\u001b[0m │                                                                       │\n",
       "│                            │ \u001b[32m.'\u001b[0m,        │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Unlike original DD notebook, `text_prompts` does not nee… │\n",
       "│                            │ \u001b[32m'yellow \u001b[0m   │ to be indexed by the timestamp. It is a list of strings.              │\n",
       "│                            │ \u001b[32mcolor \u001b[0m     │                                                                       │\n",
       "│                            │ \u001b[32mscheme'\u001b[0m\u001b[1m]\u001b[0m   │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│     transformation_percent │ \u001b[1m[\u001b[0m\u001b[1;36m0.09\u001b[0m\u001b[1m]\u001b[0m     │ Steps expressed in percentages in which the symmetry is enforced      │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│ truncate_overlength_prompt │ \u001b[3;91mFalse\u001b[0m      │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m all CLIP models use \u001b[1;36m77\u001b[0m as the context length. Set this    │\n",
       "│                            │            │ parameter truncates the prompt to the length of the model's context   │\n",
       "│                            │            │ length.                                                               │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│                   tv_scale │ \u001b[1;36m0\u001b[0m          │ Total variance denoising. Optional, set to zero to turn off. Controls │\n",
       "│                            │            │ ‘smoothness’ of final output. If used, tv_scale will try to smooth    │\n",
       "│                            │            │ out your final image to reduce overall noise. If your image is too    │\n",
       "│                            │            │ ‘crunchy’, increase tv_scale. TV denoising is good at preserving      │\n",
       "│                            │            │ edges while smoothing away noise in flat regions.  See                │\n",
       "│                            │            │ \u001b[4;94mhttps://en.wikipedia.org/wiki/Total_variation_denoising\u001b[0m               │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m Can be scheduled via syntax `*\u001b[1;36m400\u001b[0m+*\u001b[1;36m600\u001b[0m`.                  │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│    use_horizontal_symmetry │ \u001b[3;91mFalse\u001b[0m      │ Enforce symmetry over y axis of the image on  steps of the diffusion  │\n",
       "│                            │            │ process                                                               │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│        use_secondary_model │ \u001b[3;92mTrue\u001b[0m       │ Option to use a secondary purpose-made diffusion model to clean up    │\n",
       "│                            │            │ interim diffusion images for CLIP evaluation.    If this option is    │\n",
       "│                            │            │ turned off, DD will use the regular \u001b[1m(\u001b[0mlarge\u001b[1m)\u001b[0m diffusion model.    Using │\n",
       "│                            │            │ the secondary model is faster - one user reported a \u001b[1;36m50\u001b[0m% improvement   │\n",
       "│                            │            │ in render speed! However, the secondary model is much smaller, and    │\n",
       "│                            │            │ may reduce image quality and detail.  I suggest you experiment with   │\n",
       "│                            │            │ this.                                                                 │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m It can be also an boolean list schedule that represents   │\n",
       "│                            │            │ on/off on secondary model at each step, same as                       │\n",
       "│                            │            │ `clip_models_schedules` or `cut_overview`.                            │\n",
       "│                            │            │                                                                       │\n",
       "│                            │            │ Note that without secondary model it will consume higher VRAM but     │\n",
       "│                            │            │ gives better quality. Simply put, secondary model is faster, but a    │\n",
       "│                            │            │ less accurate approximation to `p_mean_variance`.                     │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│      use_vertical_symmetry │ \u001b[3;91mFalse\u001b[0m      │ Enforce symmetry over x axis of the image on  steps of the diffusion  │\n",
       "│                            │            │ process                                                               │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│             visualize_cuts │ \u001b[3;91mFalse\u001b[0m      │ \u001b[1;30;43m🆕 DiscoArt\u001b[0m If set, then `cuts-\u001b[1m{\u001b[0mstep\u001b[1m}\u001b[0m.png` will be saved for each     │\n",
       "│                            │            │ step, visualizing all cuts in a sprite image at each step.            │\n",
       "│                            │            │                                                                       │\n",
       "├────────────────────────────┼────────────┼───────────────────────────────────────────────────────────────────────┤\n",
       "│               width_height │ \u001b[1m[\u001b[0m\u001b[1;36m1280\u001b[0m,     │ Desired final image size, in pixels. You can have a square, wide, or  │\n",
       "│                            │ \u001b[1;36m768\u001b[0m\u001b[1m]\u001b[0m       │ tall image, but each edge length should be set to a multiple of 64px, │\n",
       "│                            │            │ and a minimum of 512px on the default CLIP model setting.  If you     │\n",
       "│                            │            │ forget to use multiples of 64px in your dimensions, DD will adjust    │\n",
       "│                            │            │ the dimensions of your image to make it so.                           │\n",
       "│                            │            │                                                                       │\n",
       "╰────────────────────────────┴────────────┴───────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from discoart import cheatsheet\n",
    "\n",
    "cheatsheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893ac95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "🎉 That's all you need to learn.\n",
    "\n",
    "Of course if you have some extra time, it would be helpful for you to learn the following API of DiscoArt.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Visualize results\n",
    "\n",
    "\n",
    "Final results and intermediate results are created under the current working directory, e.g.\n",
    "```text\n",
    "./{name-docarray}/{i}-step-{j}.png\n",
    "./{name-docarray}/{i}-progress.png\n",
    "./{name-docarray}/{i}-progress.gif\n",
    "./{name-docarray}/{i}-done.png\n",
    "```\n",
    "\n",
    "![](.github/result-persist.png)\n",
    "\n",
    "where:\n",
    "\n",
    "- `name-docarray` is the name of the run, you can specify it otherwise it is a random name.\n",
    "- `i-*` is up to the value of `n_batches`.\n",
    "- `*-done-*` is the final image on done.\n",
    "- `*-step-*` is the intermediate image at certain step.\n",
    "- `*-progress.png` is the sprite image of all intermediate results so far.\n",
    "- `*-progress.gif` is the animated gif of all intermediate results so far.\n",
    "\n",
    "The save frequency is controlled by `save_rate`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5020e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export configs\n",
    "\n",
    "You can review its parameters from `da[0].tags` or export it as an SVG image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a190a7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from discoart.config import save_config_svg\n",
    "\n",
    "save_config_svg(da, 'my.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d4d89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pull results anywhere anytime\n",
    "\n",
    "At anytime on any machine, you can pull the real-time results (including paramters, intermedidate diffusion steps, final results) with a session ID:\n",
    "\n",
    "> Please replace `discoart-3205998582` to your own when you run the above 2 cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8e4e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from docarray import DocumentArray\n",
    "\n",
    "da = DocumentArray.pull('discoart-3205998582')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca59262",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reuse a Document as initial state\n",
    "\n",
    "Consider a Document as a self-contained data with config and image, one can use it as the initial state for the future run. Its `.tags` will be used as the initial parameters; `.uri` if presented will be used as the initial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a95b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from discoart import create\n",
    "from docarray import DocumentArray\n",
    "\n",
    "da = DocumentArray.pull('discoart-3205998582')\n",
    "\n",
    "create(\n",
    "       init_document=da[0],\n",
    "       cut_ic_pow=0.5,\n",
    "       tv_scale=600, \n",
    "       cut_overview='[12]*1000', \n",
    "       cut_innercut='[12]*1000', \n",
    "       use_secondary_model=False,\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
